---
title: "ML Undocu imputation (SIPP to ACS)"
author: "Mario Arce Acosta"
date: "2025-03-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load raw data}
library(readr)
SIPP_2008_Wave_2 <- read_csv("C:/Users/mario/Documents/Undocu_Mismatch_Wage_Research_2024 Data/Core_TM SIPP 2008 Wave 2.csv")
View(SIPP_2008_Wave_2)
```


```{r Data preparation}
library(dplyr)
sipp08_2 <- SIPP_2008_Wave_2 %>%
  mutate(
    undocu_entry = as.factor(ifelse(timstat=="Other", 1, 0)),
    undocu_likely = as.factor(ifelse(timstat=="Other" & eadjust=="No", 1, 0)),
    education = case_when(
      eeducate == "10th Grade"  | eeducate == "11th Grade" | eeducate == "12th grade, no diploma" | eeducate == "1st, 2nd, 3rd, or 4th grade" | eeducate == "5th Or 6th Grade" | eeducate == "7th Or 8th Grade" | eeducate == "9th Grade" | eeducate == "Less Than 1st Grade"~ "No HS diploma",
      eeducate == "Diploma or certificate from a" | eeducate == "High School Graduate - (diploma" ~ "HS diploma",
      eeducate == "Some college, but no degree" ~ "Some college",
      eeducate =="Associate (2-yr) college degree" ~ "Associate's",
      eeducate == "Bachelor's degree (for example:" ~ "Bachelor's",
      eeducate == "Master's degree (For example: MA," ~ "Master's",
      eeducate == "Doctorate degree (for example:" ~ "PhD",
      TRUE ~ "Unknown" # Default case
    ),
    yrsed = case_when(
      eeducate == "10th Grade"~10,
      eeducate == "11th Grade"~11,
      eeducate == "12th grade, no diploma" | eeducate == "Diploma or certificate from a" | eeducate == "High School Graduate - (diploma" | eeducate == "Some college, but no degree" ~12,
      eeducate == "1st, 2nd, 3rd, or 4th grade"~2.5,
      eeducate == "5th Or 6th Grade"~5.5,
      eeducate == "7th Or 8th Grade"~7.5,
      eeducate == "9th Grade"~9,
      eeducate == "Less Than 1st Grade"~0,
      eeducate =="Associate (2-yr) college degree"~14,
      eeducate == "Bachelor's degree (for example:"~16,
      eeducate == "Master's degree (For example: MA,"~17.5,
      eeducate == "Doctorate degree (for example:"~22,
      eeducate == "Professional School degree (for"~16,
      TRUE ~ NA
    ),
    college = as.factor(ifelse(eeducate=="Bachelor's degree (for example:" | eeducate=="Master's degree (For example: MA," | eeducate=="Doctorate degree (for example:", 1, 0)),
    hs_only = as.factor(ifelse(eeducate=="Some college, but no degree" | eeducate== "Associate (2-yr) college degree" | eeducate=="High School Graduate - (diploma" | eeducate=="Diploma or certificate from a", 1, 0)),
    immig_yr = case_when(
      tmoveus == "1961"~1961,
      tmoveus == "1961-1968"~1966,
      tmoveus == "1969-1973"~1971,
      tmoveus == "1974-1978"~1976,
      tmoveus == "1979-1980"~1980,
      tmoveus == "1981-1983"~1982,
      tmoveus == "1984-1985"~1984,
      tmoveus == "1986-1988"~1987,
      tmoveus == "1989-1990"~1989,
      tmoveus == "1991-1992"~1991,
      tmoveus == "1993-1994"~1993,
      tmoveus == "1995-1996"~1995,
      tmoveus == "1997-1998"~1998,
      tmoveus == "1999"~1999,
      tmoveus == "2000"~2000,
      tmoveus == "2001"~2001,
      tmoveus == "2002-2003"~2002,
      tmoveus == "2004"~2004,
      tmoveus == "2005"~2005,
      tmoveus == "2006"~2006,
      tmoveus == "2007"~2007,
      tmoveus == "2008-2009"~2009,
      TRUE ~ 0 # Default case
    ),
    married = as.factor(ifelse(ems=="Married, spouse absent" | ems=="Married, spouse present", 1, 0)),
    english_difficult = as.factor(ifelse(ehowwell=="Not at all" | ehowwell=="Not well", 1, 0)),
    nonfluent = as.factor(ifelse(ehowwell=="Not at all" | ehowwell=="Not well", 1, 0)),
    english_home = as.factor(ifelse(tlang1=="Not in Universe", 1, 0)),
    spanish_hispanic_latino = as.factor(ifelse(eorigin=="Yes", 1, 0)),
    medicaid = as.factor(ifelse(rcutyp57=="Yes, covered", 1, 0)),
    household_size = ehhnumpp,
    race = case_when(
      erace=="Asian alone" ~ "Asian",
      erace=="Black alone" ~ "Black",
      erace=="White alone" ~ "White",
      erace=="Residual" ~ "Other",
      TRUE ~ "Unknown"
    ),
    asian = as.factor(ifelse(erace=="Asian alone", 1, 0)),
    black = as.factor(ifelse(erace=="Black alone", 1, 0)),
    white = as.factor(ifelse(erace=="White alone", 1, 0)),
    other_race = as.factor(ifelse(erace=="Residual", 1, 0)),
    employed = as.factor(ifelse(rmesr=="With a job at least 1 but not all" | rmesr=="With a job entire month, absent" | rmesr=="With a job entire month, worked", 1, 0)),
    years_us = rhcalyr - immig_yr,
    citizen = as.factor(ifelse(ecitizen=="Yes", 1, 0)),
    poverty = as.factor(ifelse(thearn<rhpov, 1, 0)),
    armed_forces = as.factor(ifelse(eafnow=="Yes" | eafever=="Yes", 1, 0)),
    health_ins= as.factor(ifelse(rcutyp57=="Yes, covered" | rcutyp58=="Yes, covered" , 1, 0)),
    medicare = as.factor(ifelse(ecrmth=="Yes, covered", 1, 0)),
    social_security = as.factor(ifelse(rcutyp01=="Yes, covered" | rcutyp03=="Yes, covered", 1, 0)),
    central_latino = as.factor(ifelse(tbrstate=="Central America" & eorigin=="Yes", 1, 0)),
    bpl_usa = as.factor(ifelse(ebornus=="Yes", 1, 0)),
    bpl_asia = as.factor(ifelse(tbrstate == "Eastern Asia"| tbrstate == "South Central Asia"| tbrstate == "South East Asia, West Asia,", 1, 0)),
    top_ten_states = as.factor(ifelse(tfipsst=="California" | tfipsst=="Texas" | tfipsst=="Florida" | tfipsst=="New Jersey" | tfipsst=="Illinois" | tfipsst=="New York" | tfipsst=="North Carolina" | tfipsst=="Georgia" | tfipsst=="Washington" | tfipsst=="Arizona", 1, 0))
  )

sipp08_2$bpl_foreign <- as.factor(ifelse(sipp08_2$bpl_usa==1, 0, 1))
sipp08_2$undocu_likely <- replace(sipp08_2$undocu_likely, sipp08_2$immig_yr <= 1961, 0)
sipp08_2$years_us <- ifelse(sipp08_2$years_us == 2008 | sipp08_2$years_us == 2009 | sipp08_2$years_us == -1 , NA, sipp08_2$years_us)
sipp08_2$tage <- replace(sipp08_2$tage, sipp08_2$tage == "Less than 1 full year old", 0)
sipp08_2$age <- as.numeric(sipp08_2$tage)
sipp08_2$undocu_likely <- replace(sipp08_2$undocu_likely, sipp08_2$armed_forces==1 | sipp08_2$social_security==1, 0 )
sipp08_2$undocu_logical <- as.factor(ifelse(sipp08_2$citizen==0 & (sipp08_2$armed_forces==0 | sipp08_2$medicare==0 | sipp08_2$social_security==0), 1, 0))



sipp08_2_dTable <- sipp08_2[sipp08_2$undocu_logical == 1, c("undocu_likely", "undocu_logical", "bpl_foreign", "central_latino", "bpl_asia", "age", "married", "nonfluent", "spanish_hispanic_latino", "household_size", "poverty", "asian", "black", "white", "other_race", "employed", "years_us","yrsed")]
sipp08_2_logistic <- sipp08_2[sipp08_2$undocu_logical == 1, c("undocu_likely", "central_latino", "bpl_asia", "age", "married", "nonfluent", "spanish_hispanic_latino", "household_size", "poverty", "asian", "black", "white", "other_race", "employed", "years_us","yrsed")]
sipp08_2_knn <- sipp08_2[sipp08_2$undocu_logical == 1, c("undocu_likely", "central_latino", "bpl_asia", "age", "married", "nonfluent", "spanish_hispanic_latino", "household_size", "poverty", "asian", "black", "white", "other_race", "employed", "years_us","yrsed")]
sipp08_2_rf <- sipp08_2[sipp08_2$undocu_logical == 1, c("undocu_likely", "central_latino", "bpl_asia", "age", "married", "nonfluent", "spanish_hispanic_latino", "household_size", "poverty", "asian", "black", "white", "other_race", "employed", "years_us","yrsed")]

sipp08_2_noncit <- sipp08_2[sipp08_2$citizen==0,]
sipp08_2_central_latino <- sipp08_2[sipp08_2$central_latino==1,]
sipp08_2_spanish_hispanic_latino <- sipp08_2[sipp08_2$spanish_hispanic_latino==1,]
sipp08_2_top_states <- sipp08_2[sipp08_2$top_ten_states==1,]


sipp08_2_dTable[2:17] <- sapply(sipp08_2_dTable[2:17],as.numeric)
sipp08_2_knn[2:16] <- sapply(sipp08_2_knn[2:16],as.numeric)

sipp08_2_klogistic <- na.omit(sipp08_2_logistic)
sipp08_2_dTable <- na.omit(sipp08_2_dTable)
sipp08_2_knn <- na.omit(sipp08_2_knn)
sipp08_2_rf <- na.omit(sipp08_2_rf)

View(sipp08_2)


```



```{r Logistic Regression}
library(stargazer)
library(caret)
library(xtable)


levels(sipp08_2_klogistic$undocu_likely) <- make.names(levels(sipp08_2_klogistic$undocu_likely))


set.seed(1)
train_index_klogistic <- createDataPartition(sipp08_2_klogistic$undocu_likely, p = 0.7, list = FALSE)
train_klogistic <- sipp08_2_klogistic[train_index_klogistic, ]
test_klogistic <- sipp08_2_klogistic[-train_index_klogistic, ]

## Create trainControl object
control <- trainControl(
    method = "cv",
    number = 10,  
    summaryFunction = twoClassSummary,
    classProbs = TRUE
)
## Train glm with custom trainControl
logistic_kmodel <- train(undocu_likely ~ age + married + nonfluent + spanish_hispanic_latino + central_latino + bpl_asia + household_size + poverty + asian + black + white + other_race + employed + years_us + yrsed, train_klogistic,
               method = "glm",
               trControl = control)

p_klogistic <- predict(logistic_kmodel, test_klogistic)


# Generate confusion matrix
klogistic_matrix <- confusionMatrix(p_klogistic, test_klogistic$undocu_likely, positive = "X1")
print(klogistic_matrix)
summary_logistic<-summary(logistic_kmodel)$coefficients[,c(1,4)]
summary_logistic
xtable(summary_logistic, digits=4)
```


```{r KNN}
library(class)
library(caTools)

set.seed(1)
levels(sipp08_2_knn$undocu_likely) <- make.names(levels(sipp08_2_knn$undocu_likely))
train_index_knn <- createDataPartition(sipp08_2_knn$undocu_likely, p = 0.7, list = FALSE)
train_knn <- sipp08_2_knn[train_index_knn, ]
test_knn <- sipp08_2_knn[-train_index_knn, ]



knn_model <- train(undocu_likely ~., data = train_knn, method = "knn", 
                       trControl = control, 
                       tuneLength = 10)

knn_model

predict_knn <- predict(knn_model, test_knn)


knn_matrix <- confusionMatrix(predict_knn, test_knn$undocu_likely, positive = "X1")
print(knn_matrix)
```

* The number of trees in the forest
* The number of features to consider at any given split: $m_{try}$
* The complexity of each tree
* The sampling scheme
* The splitting rule to use during tree construction
* and (2) typically have the largest impact on predictive accuracy and should always be tuned. (3) and (4) tend to have marginal impact on predictive accuracy but are still worth exploring. They also have the ability to influence computational efficiency. (5) tends to have the smallest impact on predictive accuracy and is used primarily to increase computational efficiency.


```{r Random Forest}
library(class)
library(caTools)
library(caret)
library(rpart)  ## recursive partitioning

levels(sipp08_2_rf$undocu_likely) <- make.names(levels(sipp08_2_rf$undocu_likely))


train_index_rf <- createDataPartition(sipp08_2_rf$undocu_likely, p = 0.7, list = FALSE)
train_rf <- sipp08_2_rf[train_index_rf, ]
test_rf <- sipp08_2_rf[-train_index_rf, ]

control_rf <- trainControl(
    method = "cv",
    number = 10,  
    summaryFunction = twoClassSummary,
    classProbs = TRUE
)


set.seed(1)
rf_model <- train(undocu_likely ~ age + married + nonfluent + spanish_hispanic_latino + central_latino + bpl_asia + household_size + poverty + asian + black + white + other_race + employed + years_us + yrsed,
               data = train_rf,
               method = "ranger",
               trControl = control_rf,
               tuneLength = 5,
               importance = "impurity")
print(rf_model)
plot(rf_model)

p_rf <- predict(rf_model, test_rf)

rf_matrix <- confusionMatrix(p_rf, test_rf$undocu_likely, positive="X1")
rf_matrix

feature_importance_stats<-varImp(rf_model)

library(vip)
library(gridExtra)
feature_importance <- vip(rf_model, num_features = 16, bar = FALSE)

grid.arrange(feature_importance, nrow = 1)

sipp08_2_dTable$undocu_logit <- predict(logistic_kmodel, sipp08_2_klogistic)
sipp08_2_dTable$undocu_knn <- predict(knn_model, sipp08_2_knn)
sipp08_2_dTable$undocu_rf <- predict(rf_model, sipp08_2_rf)
setwd("C:/Users/mario/Documents/Undocu_Mismatch_Wage_Research_2024 Data")
write.csv(sipp08_2_dTable, "SIPP_dTable.csv", row.names = FALSE)



#Manual search by create 10 folds and repeat 3 times
control_rf <- trainControl(method = 'repeatedcv',
                        number = 10,
                        repeats = 3,
                        search = 'grid')

tunegrid <- expand.grid(mtry = c(2,4,8,12),
                      splitrule = c("gini", "extratrees"),
                      min.node.size = 1)

#train with different ntree parameters
  set.seed(123)
rf_model_2 <- train(undocu_likely ~ age + married + nonfluent + spanish_hispanic_latino + central_latino + bpl_asia + household_size + poverty + asian + black + white + other_race + employed + years_us + yrsed,
               data = train_rf,
               method = 'ranger',
               metric = 'Accuracy',
               tuneGrid = tunegrid,
               trControl = control_rf)

print(rf_model_2)
plot(rf_model_2)

p_rf_2 <- predict(rf_model_2, test_rf)

rf_matrix_2 <- confusionMatrix(p_rf_2, test_rf$undocu_likely, positive="X1")
rf_matrix_2
```




```{r Over-fitting}
library(randomForest)

# Predictions
train_preds <- predict(rf_model, train_rf)
test_preds <- predict(rf_model, test_rf)

fit_train_preds <- predict(fit, train_rf)
fit_test_preds <- predict(fit, test_rf)

# Accuracy Calculation
train_acc <- mean(train_preds == train_rf$undocu_likely)
test_acc <- mean(test_preds == test_rf$undocu_likely)

fit_train_acc <- mean(fit_train_preds == train_rf$undocu_likely)
fit_test_acc <- mean(fit_test_preds == test_rf$undocu_likely)

cat("Training Accuracy: ", train_acc, "\n")
cat("Test Accuracy: ", test_acc, "\n")

cat("Training Accuracy: ", fit_train_acc, "\n")
cat("Test Accuracy: ", fit_test_acc, "\n")

# Extract OOB error from resampling results
oob_results <- rf_model$results

# View OOB error metrics
print(oob_results)

# Plotting OOB Error vs. mtry (number of variables tried at each split)
plot(oob_results$mtry, oob_results$Accuracy, type = "b",
     xlab = "mtry (Number of Variables Tried at Each Split)",
     ylab = "OOB Accuracy",
     main = "OOB Error vs. mtry")

print(rf_model)
plot(rf_model)


```

*undocu_likely
*age 
*married 
*nonfluent
*spanish_hispanic_latino
*central_latino
*bpl_asia
*household_size
*poverty
*asian
*black
*white
*other_race 
*employed
*years_us
*yrsed

```{r Loading ACS data}
library(readr)
setwd("C:/Users/mario/Documents/Undocu_Mismatch_Wage_Research_2024 Data")
ACS <- read_csv("ACS.csv")
View(ACS)

```

```{r Preparing ACS data}
ACS_sipp <- ACS %>%
  mutate(
    spanish_hispanic_latino = as.factor(ifelse(hisp==1 | spanish==1, 1, 0)),
    central_latino = as.factor(ifelse((hisp==1) & (bpld=="belize/british honduras" | bpld=="costa rica" | bpld=="el salvador" | bpld=="guatemala" | bpld=="honduras" | bpld=="nicaragua" | bpld=="panama" | bpld=="mexico"), 1, 0)),
    black = as.factor(ifelse(race=="black/african america", 1, 0)),
    white = as.factor(ifelse(race=="white", 1, 0)),
    employed = as.factor(ifelse(empstat==1, 1, 0)),
    poverty = as.factor(ifelse(poverty<100, 1, 0)),
    married = as.factor(married),
    nonfluent = as.factor(nonfluent),
    bpl_asia = as.factor(bpl_asia),
    asian = as.factor(asian),
    household_size = numprec,
    #Change SIPP 0 years_us to NA
    years_us = yrsusa1,
    medicare = as.factor(ifelse(hinscare=="yes", 1, 0))
    
  )
ACS_sipp$years_us <- replace(ACS_sipp$years_us, ACS_sipp$yrsusa1=="n/a or less than one year" & ACS_sipp$bpl_usa==1, NA)
ACS_sipp$years_us <- replace(ACS_sipp$years_us, ACS_sipp$yrsusa1=="n/a or less than one year" & ACS_sipp$bpl_usa==0, 0)
ACS_sipp$years_us <- as.numeric(ACS_sipp$years_us)

ACS_sipp$other_race <- as.factor(ifelse(ACS$black!=1 & ACS$white!=1 & ACS$asian!=1, 1, 0))
ACS_sipp_na <- ACS_sipp  %>%
  filter(undocu==1, !is.na(age), !is.na(married), !is.na(nonfluent), !is.na(spanish_hispanic_latino), !is.na(central_latino), !is.na(bpl_asia), !is.na(household_size), !is.na(poverty), !is.na(asian), !is.na(black), !is.na(white), !is.na(other_race), !is.na(employed), !is.na(years_us), !is.na(yrsed)
         )

ACS_cols_numeric <- c("central_latino", "bpl_asia", "age", "married", "nonfluent", "spanish_hispanic_latino", "household_size", "poverty", "asian", "black", "white", "other_race", "employed", "years_us","yrsed")

ACS_sipp_knn <- ACS_sipp_na %>%
  mutate_at(ACS_cols_numeric, as.numeric)
```

```{r Undocu imputation}
## Imputation method 1: Logistic regression 
ACS_sipp_na$undocu_logistic <- predict(logistic_kmodel, ACS_sipp_na)
setwd("C:/Users/mario/Documents/Undocu_Mismatch_Wage_Research_2024 Data")
write.csv(ACS_sipp_na, "ACS_SIPP_logistic.csv", row.names = FALSE)

## Imputation method 2: KNN 
ACS_sipp_na$knn_undocu <- predict(knn_model, ACS_sipp_knn)
setwd("C:/Users/mario/Documents/Undocu_Mismatch_Wage_Research_2024 Data")
write.csv(ACS_sipp_na, "ACS_SIPP_knn.csv", row.names = FALSE)

## Imputation method 2: RF 
ACS_sipp_na$rf_undocu <- predict(rf_model, ACS_sipp_na)
setwd("C:/Users/mario/Documents/Undocu_Mismatch_Wage_Research_2024 Data")
write.csv(ACS_sipp_na, "ACS_SIPP_rf.csv", row.names = FALSE)
```

```{r Logical edits performance}
## General
FN_logical <- length(which(sipp08_2$undocu_logical==0 & sipp08_2$undocu_likely==1))
TN_logical <- length(which(sipp08_2$undocu_logical==0 & sipp08_2$undocu_likely==0))
FP_logical <- length(which(sipp08_2$undocu_logical==1 & sipp08_2$undocu_likely==0))
TP_logical <- length(which(sipp08_2$undocu_logical==1 & sipp08_2$undocu_likely==1))

specificity_logical<- TN_logical/(TN_logical+FP_logical)
sensitivity_logical<- TP_logical/(TP_logical+FN_logical)
ppv_logical <- TP_logical/(TP_logical+FP_logical)
accuracy_logical <- (TP_logical+TN_logical)/(TP_logical+TN_logical+FP_logical+FN_logical)  

## Noncitizens
FN_logical_noncit <- length(which(sipp08_2_noncit$undocu_logical==0 & sipp08_2_noncit$undocu_likely==1))
TN_logical_noncit <- length(which(sipp08_2_noncit$undocu_logical==0 & sipp08_2_noncit$undocu_likely==0))
FP_logical_noncit <- length(which(sipp08_2_noncit$undocu_logical==1 & sipp08_2_noncit$undocu_likely==0))
TP_logical_noncit <- length(which(sipp08_2_noncit$undocu_logical==1 & sipp08_2_noncit$undocu_likely==1))

specificity_logical_noncit<- TN_logical_noncit/(TN_logical_noncit+FP_logical_noncit)
sensitivity_logical_noncit<- TP_logical_noncit/(TP_logical_noncit+FN_logical_noncit)
ppv_logical_noncit <- TP_logical_noncit/(TP_logical_noncit+FP_logical_noncit)
accuracy_logical_noncit <- (TP_logical_noncit+TN_logical_noncit)/(TP_logical_noncit+TN_logical_noncit+FP_logical_noncit+FN_logical_noncit)  

## Top ten states of undocumented immigrants
FN_logical_top_states <- length(which(sipp08_2_top_states$undocu_logical==0 & sipp08_2_top_states$undocu_likely==1))
TN_logical_top_states <- length(which(sipp08_2_top_states$undocu_logical==0 & sipp08_2_top_states$undocu_likely==0))
FP_logical_top_states <- length(which(sipp08_2_top_states$undocu_logical==1 & sipp08_2_top_states$undocu_likely==0))
TP_logical_top_states <- length(which(sipp08_2_top_states$undocu_logical==1 & sipp08_2_top_states$undocu_likely==1))

specificity_logical_top_states<- TN_logical_top_states/(TN_logical_top_states+FP_logical_top_states)
sensitivity_logical_top_states<- TP_logical_top_states/(TP_logical_top_states+FN_logical_top_states)
ppv_logical_top_states <- TP_logical_top_states/(TP_logical_top_states+FP_logical_top_states)
accuracy_logical_top_states <- (TP_logical_top_states+TN_logical_top_states)/(TP_logical_top_states+TN_logical_top_states+FP_logical_top_states+FN_logical_top_states)  

## Hispanic, latino, spanish
FN_logical_spanish_hispanic_latino <- length(which(sipp08_2_spanish_hispanic_latino$undocu_logical==0 & sipp08_2_spanish_hispanic_latino$undocu_likely==1))
TN_logical_spanish_hispanic_latino <- length(which(sipp08_2_spanish_hispanic_latino$undocu_logical==0 & sipp08_2_spanish_hispanic_latino$undocu_likely==0))
FP_logical_spanish_hispanic_latino <- length(which(sipp08_2_spanish_hispanic_latino$undocu_logical==1 & sipp08_2_spanish_hispanic_latino$undocu_likely==0))
TP_logical_spanish_hispanic_latino <- length(which(sipp08_2_spanish_hispanic_latino$undocu_logical==1 & sipp08_2_spanish_hispanic_latino$undocu_likely==1))

specificity_logical_spanish_hispanic_latino<- TN_logical_spanish_hispanic_latino/(TN_logical_spanish_hispanic_latino+FP_logical_spanish_hispanic_latino)
sensitivity_logical_spanish_hispanic_latino<- TP_logical_spanish_hispanic_latino/(TP_logical_spanish_hispanic_latino+FN_logical_spanish_hispanic_latino)
ppv_logical_spanish_hispanic_latino <- TP_logical_spanish_hispanic_latino/(TP_logical_spanish_hispanic_latino+FP_logical_spanish_hispanic_latino)
accuracy_logical_spanish_hispanic_latino <- (TP_logical_spanish_hispanic_latino+TN_logical_spanish_hispanic_latino)/(TP_logical_spanish_hispanic_latino+TN_logical_spanish_hispanic_latino+FP_logical_spanish_hispanic_latino+FN_logical_spanish_hispanic_latino)  

## Central America and Latino (Central America + Mexico)
FN_logical_central_latino <- length(which(sipp08_2_central_latino$undocu_logical==0 & sipp08_2_central_latino$undocu_likely==1))
TN_logical_central_latino <- length(which(sipp08_2_central_latino$undocu_logical==0 & sipp08_2_central_latino$undocu_likely==0))
FP_logical_central_latino <- length(which(sipp08_2_central_latino$undocu_logical==1 & sipp08_2_central_latino$undocu_likely==0))
TP_logical_central_latino <- length(which(sipp08_2_central_latino$undocu_logical==1 & sipp08_2_central_latino$undocu_likely==1))


specificity_logical_central_latino<- TN_logical_central_latino/(TN_logical_central_latino+FP_logical_central_latino)
sensitivity_logical_central_latino<- TP_logical_central_latino/(TP_logical_central_latino+FN_logical_central_latino)
ppv_logical_central_latino <- TP_logical_central_latino/(TP_logical_central_latino+FP_logical_central_latino)
accuracy_logical_central_latino <- (TP_logical_central_latino+TN_logical_central_latino)/(TP_logical_central_latino+TN_logical_central_latino+FP_logical_central_latino+FN_logical_central_latino)



logical_sensitivity <- c(sensitivity_logical, sensitivity_logical_noncit, sensitivity_logical_top_states, sensitivity_logical_spanish_hispanic_latino, sensitivity_logical_central_latino)

logical_specificity <- c(specificity_logical, specificity_logical_noncit, specificity_logical_top_states, specificity_logical_spanish_hispanic_latino, specificity_logical_central_latino)

logical_ppv <- c(ppv_logical, ppv_logical_noncit, ppv_logical_top_states, ppv_logical_spanish_hispanic_latino, ppv_logical_central_latino)

logical_accuracy <- c(accuracy_logical, accuracy_logical_noncit, accuracy_logical_top_states, accuracy_logical_spanish_hispanic_latino, accuracy_logical_central_latino)


logical_edits_table <- data.frame(logical_sensitivity, logical_specificity, logical_ppv, logical_accuracy)
logical_edits_comparison <- as.data.frame(t(logical_edits_table))
colnames(logical_edits_comparison) <- c("Initial SIPP sample", "Noncitizens", "Top 10 states", "Hispanic/Latino/Spanish", "Central America and Latino")

# Logical edits metrics (comparison of Logical edits filters)
xtable(logical_edits_comparison, digits=4)
print(logical_edits_comparison)
```

https://bradleyboehmke.github.io/HOML/process.html
Sensitivity: $\frac{TP}{TP + FN}$
Specificity: $\frac{TN}{TN + FP}$
Precision / Positive-predictive value: $\frac{TP}{TP + FP}$
Accuracy: $\frac{TP + TN}{total}$

```{r General Model performance}
library(pROC)
library(xtable)





## Model comparison table creation
# ML statistics
accuracy <- c(accuracy_logical, klogistic_matrix$overall[['Accuracy']], knn_matrix$overall[['Accuracy']], rf_matrix$overall[['Accuracy']])

sensitivity <- c(sensitivity_logical, klogistic_matrix$byClass[['Sensitivity']], knn_matrix$byClass[['Sensitivity']], rf_matrix$byClass[['Sensitivity']])

specificity <- c(specificty_logical, klogistic_matrix$byClass[['Specificity']], knn_matrix$byClass[['Specificity']], rf_matrix$byClass[['Specificity']])

ppv <- c(ppv_logical, klogistic_matrix$byClass[['Pos Pred Value']], knn_matrix$byClass[['Pos Pred Value']],rf_matrix$byClass[['Pos Pred Value']])


ml_table <- data.frame(sensitivity, specificity, ppv, accuracy)
ml_comparison <- as.data.frame(t(ml_table))
colnames(ml_comparison) <- c("Logical edits", "Logistic", "KNN", "RF")

# ML metrics (comparison of ML models)
xtable(ml_comparison, digits=4)
print(ml_comparison)
```


